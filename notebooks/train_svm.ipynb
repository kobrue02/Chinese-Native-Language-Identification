{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnkSQpYxvu6v"
   },
   "source": [
    "# Traditional ML (SVM Features) for Chinese NLI\n",
    "\n",
    "Extract hand-crafted features and train classifiers (LogReg, SGD, SVM, MLP).\n",
    "\n",
    "**Instructions:**\n",
    "1. Upload `NNP.zip` to your Google Drive under `NNP.zip`\n",
    "   - Create locally: `cd ~/Desktop/uni && zip -r NNP.zip NNP/ -x 'NNP/.venv/*' 'NNP/.git/*' 'NNP/results/*'`\n",
    "2. Run all cells (GPU not required but speeds up jieba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7br7cNF0vu6w"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import zipfile, os, sys\n",
    "\n",
    "ZIP_PATH = '/content/drive/MyDrive/NNP/NNP.zip'\n",
    "LOCAL_DIR = '/content/NNP'\n",
    "\n",
    "with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
    "    zf.extractall('/content')\n",
    "\n",
    "os.chdir(LOCAL_DIR)\n",
    "sys.path.insert(0, LOCAL_DIR)\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPJF_VNUvu6x"
   },
   "outputs": [],
   "source": [
    "!pip install -q jieba scikit-learn tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVVjiM0bvu6x"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "from data_loader import load_and_split\n",
    "from features import build_features\n",
    "from models.svm import build_classifier, grid_search_svm\n",
    "from evaluate import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_79QPBy8vu6x"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGMbQVPbvu6x"
   },
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "train, val, test, le = load_and_split()\n",
    "label_names = list(le.classes_)\n",
    "print(f'Train: {len(train)}  Val: {len(val)}  Test: {len(test)}  Classes: {len(label_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urIZzsTkvu6x"
   },
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKNdC9dAvu6x"
   },
   "outputs": [],
   "source": [
    "USE_RADICALS = True   # set to False if data/radical_map.json is missing\n",
    "USE_DEPENDENCY = False  # requires spaCy zh_core_web_sm\n",
    "\n",
    "print('Extracting features...')\n",
    "t0 = time.time()\n",
    "X_train, X_val, X_test, _ = build_features(\n",
    "    train['text'].tolist(),\n",
    "    val['text'].tolist(),\n",
    "    test['text'].tolist(),\n",
    "    use_radicals=USE_RADICALS,\n",
    "    use_dependency=USE_DEPENDENCY,\n",
    ")\n",
    "print(f'Feature extraction took {time.time() - t0:.1f}s')\n",
    "print(f'Feature matrix shape: {X_train.shape}')\n",
    "\n",
    "y_train = train['label'].values\n",
    "y_val = val['label'].values\n",
    "y_test = test['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_hP_mrFvu6x"
   },
   "source": [
    "## Train All Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "source": "CLASSIFIERS = ['logreg', 'sgd', 'svm', 'mlp']\n\nrows = []\nfor name in CLASSIFIERS:\n    print(f'\\n{\"=\" * 50}')\n    print(f'Training: {name}')\n    print(f'{\"=\" * 50}')\n\n    clf = build_classifier(name)\n    t0 = time.time()\n    clf.fit(X_train_raw, y_train)\n    train_time = time.time() - t0\n    print(f'Training took {train_time:.1f}s')\n\n    val_metrics = compute_metrics(y_val, clf.predict(X_val_raw), label_names)\n    test_metrics = compute_metrics(y_test, clf.predict(X_test_raw), label_names)\n\n    row = {\n        'model': name,\n        'val_acc': val_metrics['accuracy'],\n        'val_f1': val_metrics['macro_f1'],\n        'val_wf1': val_metrics['weighted_f1'],\n        'test_acc': test_metrics['accuracy'],\n        'test_f1': test_metrics['macro_f1'],\n        'test_wf1': test_metrics['weighted_f1'],\n        'time_s': f'{train_time:.1f}',\n    }\n    rows.append(row)\n    print(f\"  val_acc={row['val_acc']:.4f}  val_f1={row['val_f1']:.4f}\")\n    print(f\"  test_acc={row['test_acc']:.4f}  test_f1={row['test_f1']:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiJ5vC-kvu6y"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnbrTjW7vu6y"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(rows)\n",
    "display(results.style.format({\n",
    "    'val_acc': '{:.4f}', 'val_f1': '{:.4f}', 'val_wf1': '{:.4f}',\n",
    "    'test_acc': '{:.4f}', 'test_f1': '{:.4f}', 'test_wf1': '{:.4f}',\n",
    "}).set_caption('Traditional ML Results (hand-crafted features)'))\n",
    "\n",
    "# Save CSV\n",
    "config.RESULTS_DIR.mkdir(exist_ok=True)\n",
    "csv_path = config.RESULTS_DIR / 'svm_results.csv'\n",
    "results.to_csv(csv_path, index=False)\n",
    "print(f'Saved {csv_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Qj_gGqjvu6y"
   },
   "outputs": [],
   "source": [
    "# \u2500\u2500 Bar chart \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "x = range(len(results))\n",
    "w = 0.35\n",
    "ax.bar([i - w/2 for i in x], results['test_acc'], w, label='Test Accuracy')\n",
    "ax.bar([i + w/2 for i in x], results['test_f1'], w, label='Test Macro-F1')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results['model'])\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Traditional ML \u2014 Hand-crafted Features')\n",
    "ax.legend()\n",
    "for i, (acc, f1) in enumerate(zip(results['test_acc'], results['test_f1'])):\n",
    "    ax.text(i - w/2, acc + 0.01, f'{acc:.3f}', ha='center', fontsize=8)\n",
    "    ax.text(i + w/2, f1 + 0.01, f'{f1:.3f}', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWh7rHuTvu6y"
   },
   "outputs": [],
   "source": [
    "# \u2500\u2500 LaTeX table \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "lines = [\n",
    "    r'\\begin{table}[htbp]',\n",
    "    r'\\centering',\n",
    "    r'\\caption{Traditional ML results (hand-crafted features).}',\n",
    "    r'\\label{tab:svm-results}',\n",
    "    r'\\begin{tabular}{lrrrr}',\n",
    "    r'\\toprule',\n",
    "    r'\\textbf{Model} & \\textbf{Val Acc} & \\textbf{Val F1} & \\textbf{Test Acc} & \\textbf{Test F1} \\\\',\n",
    "    r'\\midrule',\n",
    "]\n",
    "for _, r in results.iterrows():\n",
    "    lines.append(\n",
    "        f\"{r['model']} & {r['val_acc']:.4f} & {r['val_f1']:.4f} & \"\n",
    "        f\"{r['test_acc']:.4f} & {r['test_f1']:.4f} \\\\\\\\\"\n",
    "    )\n",
    "lines += [r'\\bottomrule', r'\\end{tabular}', r'\\end{table}']\n",
    "\n",
    "tex = '\\n'.join(lines)\n",
    "print(tex)\n",
    "\n",
    "tex_path = config.RESULTS_DIR / 'svm_results.tex'\n",
    "tex_path.write_text(tex)\n",
    "print(f'\\nSaved {tex_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZHE3R1Qvu6y"
   },
   "outputs": [],
   "source": [
    "# Copy results to Drive\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "drive_results = Path('/content/drive/MyDrive/NNP_results')\n",
    "drive_results.mkdir(exist_ok=True)\n",
    "for f in config.RESULTS_DIR.iterdir():\n",
    "    shutil.copy2(f, drive_results / f.name)\n",
    "print(f'Copied results to {drive_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Feature Ablation Study\n\nExtract each of the 9 feature groups independently, then run 19 MLP trainings:\n- 1 full baseline (all 9 groups)\n- 9 leave-one-out (drop one group at a time, measure F1 drop)\n- 9 individual (each group alone)\n\nPipeline per run: `hstack \u2192 TruncatedSVD(300) \u2192 StandardScaler \u2192 MLPClassifier(512, 256)`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from collections import OrderedDict\nimport json\nimport scipy.sparse as sp\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\n\nfrom features.ngrams import char_ngram_vectorizer, word_ngram_vectorizer\nfrom features.pos_tags import extract_pos_features\nfrom features.pos_ngrams import pos_ngram_vectorizer, pos_to_sequences\nfrom features.function_words import extract_function_word_features\nfrom features.particles import extract_particle_features\nfrom features.discourse import extract_discourse_features\nfrom features.lexical_richness import extract_lexical_richness_features\nfrom features.segmentation import extract_segmentation_features\n\nGROUPS = OrderedDict([\n    ('char',   'Char n-grams'),\n    ('word',   'Word n-grams'),\n    ('pos',    'POS tags'),\n    ('pos_ng', 'POS n-grams'),\n    ('func',   'Function words'),\n    ('part',   'Particles'),\n    ('disc',   'Discourse'),\n    ('lex',    'Lexical richness'),\n    ('seg',    'Segmentation'),\n])\n\ntrain_texts = train['text'].tolist()\ntest_texts  = test['text'].tolist()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \u2500\u2500 Extract all 9 feature groups independently \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _sparse(arr):\n    return sp.csr_matrix(arr)\n\nblocks = {}\nprint('Extracting 9 feature groups independently...')\nt0 = time.time()\n\nprint('  [1/9] Character n-gram TF-IDF...')\nvec = char_ngram_vectorizer()\nblocks['char'] = (vec.fit_transform(train_texts), vec.transform(test_texts))\n\nprint('  [2/9] Word n-gram TF-IDF (jieba)...')\nword_vec, jieba_tok = word_ngram_vectorizer()\njieba_tok.set_total(len(train_texts), desc='    fit (train)')\ntr = word_vec.fit_transform(train_texts)\njieba_tok.close()\njieba_tok.set_total(len(test_texts), desc='    transform (test)')\nte = word_vec.transform(test_texts)\njieba_tok.close()\nblocks['word'] = (tr, te)\n\nprint('  [3/9] POS tag distributions...')\nblocks['pos'] = (_sparse(extract_pos_features(train_texts)),\n                 _sparse(extract_pos_features(test_texts)))\n\nprint('  [4/9] POS n-gram TF-IDF...')\ntrain_seq = pos_to_sequences(train_texts, desc='    POS seq (train)')\ntest_seq  = pos_to_sequences(test_texts,  desc='    POS seq (test)')\npv = pos_ngram_vectorizer()\nblocks['pos_ng'] = (pv.fit_transform(train_seq), pv.transform(test_seq))\n\nprint('  [5/9] Function word frequencies...')\nblocks['func'] = (_sparse(extract_function_word_features(train_texts)),\n                  _sparse(extract_function_word_features(test_texts)))\n\nprint('  [6/9] Particle context features...')\nblocks['part'] = (_sparse(extract_particle_features(train_texts)),\n                  _sparse(extract_particle_features(test_texts)))\n\nprint('  [7/9] Discourse connectives & sentence features...')\nblocks['disc'] = (_sparse(extract_discourse_features(train_texts)),\n                  _sparse(extract_discourse_features(test_texts)))\n\nprint('  [8/9] Lexical richness features...')\nblocks['lex'] = (_sparse(extract_lexical_richness_features(train_texts)),\n                 _sparse(extract_lexical_richness_features(test_texts)))\n\nprint('  [9/9] Segmentation-derived features...')\nblocks['seg'] = (_sparse(extract_segmentation_features(train_texts)),\n                 _sparse(extract_segmentation_features(test_texts)))\n\nprint(f'\\nExtraction took {time.time() - t0:.1f}s')\nfor key, name in GROUPS.items():\n    print(f'  {name:<20s} {blocks[key][0].shape[1]:>6d} dims')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \u2500\u2500 Helper: combine selected blocks and train MLP \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef combine_blocks(blocks, keys):\n    train_parts = [blocks[k][0] for k in keys]\n    test_parts  = [blocks[k][1] for k in keys]\n    return sp.hstack(train_parts, format='csr'), sp.hstack(test_parts, format='csr')\n\ndef train_and_predict(X_train, y_train, X_test, run_label=''):\n    n_components = min(300, X_train.shape[1], X_train.shape[0])\n    svd = TruncatedSVD(n_components=n_components, random_state=config.RANDOM_SEED)\n    X_tr = svd.fit_transform(X_train)\n    X_te = svd.transform(X_test)\n    explained = svd.explained_variance_ratio_.sum()\n    scaler = StandardScaler()\n    X_tr = scaler.fit_transform(X_tr)\n    X_te = scaler.transform(X_te)\n    clf = MLPClassifier(hidden_layer_sizes=(512, 256), early_stopping=True,\n                        random_state=config.RANDOM_SEED, max_iter=300)\n    clf.fit(X_tr, y_train)\n    print(f'  {run_label}: {X_train.shape[1]} feats -> {n_components} SVD '\n          f'({explained:.1%} var), MLP epoch {clf.n_iter_}')\n    return clf.predict(X_te)\n\n# \u2500\u2500 Run all 19 experiments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nkeys = list(GROUPS.keys())\nablation = {}\n\n# Full baseline\nprint('== Full baseline (all 9 groups) ==')\nX_tr, X_te = combine_blocks(blocks, keys)\ny_pred = train_and_predict(X_tr, y_train, X_te, 'ALL')\nm = compute_metrics(y_test, y_pred, label_names)\nablation['full'] = {'accuracy': m['accuracy'], 'macro_f1': m['macro_f1']}\nprint(f'  -> Acc={m[\"accuracy\"]:.4f}  F1={m[\"macro_f1\"]:.4f}')\nfull_f1 = m['macro_f1']\n\n# Leave-one-out\nprint('\\n== Leave-one-out ==')\nloo = {}\nfor drop in keys:\n    subset = [k for k in keys if k != drop]\n    X_tr, X_te = combine_blocks(blocks, subset)\n    y_pred = train_and_predict(X_tr, y_train, X_te, f'LOO-{drop}')\n    m = compute_metrics(y_test, y_pred, label_names)\n    delta = m['macro_f1'] - full_f1\n    loo[drop] = {'accuracy': m['accuracy'], 'macro_f1': m['macro_f1'], 'delta_f1': delta}\n    print(f'  -> Acc={m[\"accuracy\"]:.4f}  F1={m[\"macro_f1\"]:.4f}  dF1={delta:+.4f}')\nablation['loo'] = loo\n\n# Individual\nprint('\\n== Individual groups ==')\nind = {}\nfor key in keys:\n    X_tr, X_te = combine_blocks(blocks, [key])\n    y_pred = train_and_predict(X_tr, y_train, X_te, f'SOLO-{key}')\n    m = compute_metrics(y_test, y_pred, label_names)\n    ind[key] = {'accuracy': m['accuracy'], 'macro_f1': m['macro_f1']}\n    print(f'  -> Acc={m[\"accuracy\"]:.4f}  F1={m[\"macro_f1\"]:.4f}')\nablation['individual'] = ind",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \u2500\u2500 Results table \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nabl_rows = []\nfor key, name in GROUPS.items():\n    abl_rows.append({\n        'Group': name,\n        'Ind Acc':  ablation['individual'][key]['accuracy'],\n        'Ind F1':   ablation['individual'][key]['macro_f1'],\n        'LOO Acc':  ablation['loo'][key]['accuracy'],\n        'LOO F1':   ablation['loo'][key]['macro_f1'],\n        'dF1':      ablation['loo'][key]['delta_f1'],\n    })\n\nabl_df = pd.DataFrame(abl_rows)\nprint(f\"Full baseline: Acc={ablation['full']['accuracy']:.4f}  \"\n      f\"F1={ablation['full']['macro_f1']:.4f}\\n\")\ndisplay(abl_df.style.format({\n    'Ind Acc': '{:.4f}', 'Ind F1': '{:.4f}',\n    'LOO Acc': '{:.4f}', 'LOO F1': '{:.4f}', 'dF1': '{:+.4f}',\n}).set_caption('Feature Group Ablation (MLP)'))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \u2500\u2500 Bar chart: LOO F1 drop per group \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nsorted_keys = sorted(ablation['loo'], key=lambda k: ablation['loo'][k]['delta_f1'])\nnames  = [GROUPS[k] for k in sorted_keys]\ndeltas = [ablation['loo'][k]['delta_f1'] for k in sorted_keys]\n\nfig, ax = plt.subplots(figsize=(8, 5))\ncolors = ['#d62728' if d < 0 else '#2ca02c' for d in deltas]\ny_pos = range(len(names))\nax.barh(y_pos, deltas, color=colors, edgecolor='none', height=0.6)\nax.set_yticks(y_pos)\nax.set_yticklabels(names, fontsize=9)\nax.set_xlabel('dF1 (drop from full model)')\nax.set_title('Feature Group Importance (Leave-One-Out F1 Drop)')\nax.axvline(0, color='black', linewidth=0.5)\nfor i, d in enumerate(deltas):\n    ha = 'right' if d < 0 else 'left'\n    offset = -0.001 if d < 0 else 0.001\n    ax.text(d + offset, i, f'{d:+.4f}', va='center', ha=ha, fontsize=8)\nfig.tight_layout()\n\npath_png = config.RESULTS_DIR / 'ablation_feature_importance.png'\npath_pdf = config.RESULTS_DIR / 'ablation_feature_importance.pdf'\nfig.savefig(path_png, dpi=150, bbox_inches='tight')\nfig.savefig(path_pdf, bbox_inches='tight')\nplt.show()\nprint(f'Saved {path_png}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# \u2500\u2500 LaTeX table + JSON \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfull_acc = ablation['full']['accuracy']\nfull_f1  = ablation['full']['macro_f1']\n\nlines = [\n    r'\\begin{table}[htbp]',\n    r'\\centering',\n    r'\\caption{Feature group ablation study (MLP). '\n    r'Full model: Acc=%.4f, F1=%.4f.}' % (full_acc, full_f1),\n    r'\\label{tab:feature-ablation}',\n    r'\\begin{tabular}{lrrrrr}',\n    r'\\toprule',\n    r'\\textbf{Feature Group} & \\textbf{Ind.\\ Acc} & \\textbf{Ind.\\ F1} '\n    r'& \\textbf{LOO Acc} & \\textbf{LOO F1} & \\textbf{$\\Delta$F1} \\\\',\n    r'\\midrule',\n]\nfor key, name in GROUPS.items():\n    i = ablation['individual'][key]\n    l = ablation['loo'][key]\n    lines.append(\n        f\"{name} & {i['accuracy']:.4f} & {i['macro_f1']:.4f} \"\n        f\"& {l['accuracy']:.4f} & {l['macro_f1']:.4f} \"\n        f\"& {l['delta_f1']:+.4f} \\\\\\\\\"\n    )\nlines += [r'\\bottomrule', r'\\end{tabular}', r'\\end{table}']\ntex = '\\n'.join(lines)\nprint(tex)\n\ntex_path = config.RESULTS_DIR / 'ablation_feature_importance.tex'\ntex_path.write_text(tex)\nprint(f'\\nSaved {tex_path}')\n\n# Save JSON\njson_path = config.RESULTS_DIR / 'ablation_results.json'\nwith open(json_path, 'w') as f:\n    json.dump(ablation, f, indent=2)\nprint(f'Saved {json_path}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Copy updated results to Drive\nfor f in config.RESULTS_DIR.iterdir():\n    shutil.copy2(f, drive_results / f.name)\nprint(f'Copied results to {drive_results}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}