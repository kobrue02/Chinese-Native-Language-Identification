{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnkSQpYxvu6v"
      },
      "source": [
        "# Traditional ML (SVM Features) for Chinese NLI\n",
        "\n",
        "Extract hand-crafted features and train classifiers (LogReg, SGD, SVM, MLP).\n",
        "\n",
        "**Instructions:**\n",
        "1. Upload `NNP.zip` to your Google Drive under `NNP.zip`\n",
        "   - Create locally: `cd ~/Desktop/uni && zip -r NNP.zip NNP/ -x 'NNP/.venv/*' 'NNP/.git/*' 'NNP/results/*'`\n",
        "2. Run all cells (GPU not required but speeds up jieba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7br7cNF0vu6w"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile, os, sys\n",
        "\n",
        "ZIP_PATH = '/content/drive/MyDrive/NNP/NNP.zip'\n",
        "LOCAL_DIR = '/content/NNP'\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, 'r') as zf:\n",
        "    zf.extractall('/content')\n",
        "\n",
        "os.chdir(LOCAL_DIR)\n",
        "sys.path.insert(0, LOCAL_DIR)\n",
        "print(f'Working directory: {os.getcwd()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPJF_VNUvu6x"
      },
      "outputs": [],
      "source": [
        "!pip install -q jieba scikit-learn tqdm scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVVjiM0bvu6x"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import config\n",
        "from data_loader import load_and_split\n",
        "from features import build_features\n",
        "from models.svm import build_classifier, grid_search_svm\n",
        "from evaluate import compute_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_79QPBy8vu6x"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGMbQVPbvu6x"
      },
      "outputs": [],
      "source": [
        "print('Loading data...')\n",
        "train, val, test, le = load_and_split()\n",
        "label_names = list(le.classes_)\n",
        "print(f'Train: {len(train)}  Val: {len(val)}  Test: {len(test)}  Classes: {len(label_names)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urIZzsTkvu6x"
      },
      "source": [
        "## Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKNdC9dAvu6x"
      },
      "outputs": [],
      "source": [
        "USE_RADICALS = True   # set to False if data/radical_map.json is missing\n",
        "USE_DEPENDENCY = False  # requires spaCy zh_core_web_sm\n",
        "\n",
        "print('Extracting features...')\n",
        "t0 = time.time()\n",
        "X_train, X_val, X_test, _ = build_features(\n",
        "    train['text'].tolist(),\n",
        "    val['text'].tolist(),\n",
        "    test['text'].tolist(),\n",
        "    use_radicals=USE_RADICALS,\n",
        "    use_dependency=USE_DEPENDENCY,\n",
        ")\n",
        "print(f'Feature extraction took {time.time() - t0:.1f}s')\n",
        "print(f'Feature matrix shape: {X_train.shape}')\n",
        "\n",
        "y_train = train['label'].values\n",
        "y_val = val['label'].values\n",
        "y_test = test['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_hP_mrFvu6x"
      },
      "source": [
        "## Train All Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNd6EXDLvu6y"
      },
      "outputs": [],
      "source": [
        "CLASSIFIERS = ['logreg', 'sgd', 'svm', 'mlp']\n",
        "\n",
        "rows = []\n",
        "for name in CLASSIFIERS:\n",
        "    print(f'\\n{\"=\" * 50}')\n",
        "    print(f'Training: {name}')\n",
        "    print(f'{\"=\" * 50}')\n",
        "\n",
        "    clf = build_classifier(name)\n",
        "    t0 = time.time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_time = time.time() - t0\n",
        "    print(f'Training took {train_time:.1f}s')\n",
        "\n",
        "    val_metrics = compute_metrics(y_val, clf.predict(X_val), label_names)\n",
        "    test_metrics = compute_metrics(y_test, clf.predict(X_test), label_names)\n",
        "\n",
        "    row = {\n",
        "        'model': name,\n",
        "        'val_acc': val_metrics['accuracy'],\n",
        "        'val_f1': val_metrics['macro_f1'],\n",
        "        'val_wf1': val_metrics['weighted_f1'],\n",
        "        'test_acc': test_metrics['accuracy'],\n",
        "        'test_f1': test_metrics['macro_f1'],\n",
        "        'test_wf1': test_metrics['weighted_f1'],\n",
        "        'time_s': f'{train_time:.1f}',\n",
        "    }\n",
        "    rows.append(row)\n",
        "    print(f\"  val_acc={row['val_acc']:.4f}  val_f1={row['val_f1']:.4f}\")\n",
        "    print(f\"  test_acc={row['test_acc']:.4f}  test_f1={row['test_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiJ5vC-kvu6y"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnbrTjW7vu6y"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(rows)\n",
        "display(results.style.format({\n",
        "    'val_acc': '{:.4f}', 'val_f1': '{:.4f}', 'val_wf1': '{:.4f}',\n",
        "    'test_acc': '{:.4f}', 'test_f1': '{:.4f}', 'test_wf1': '{:.4f}',\n",
        "}).set_caption('Traditional ML Results (hand-crafted features)'))\n",
        "\n",
        "# Save CSV\n",
        "config.RESULTS_DIR.mkdir(exist_ok=True)\n",
        "csv_path = config.RESULTS_DIR / 'svm_results.csv'\n",
        "results.to_csv(csv_path, index=False)\n",
        "print(f'Saved {csv_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qj_gGqjvu6y"
      },
      "outputs": [],
      "source": [
        "# ── Bar chart ─────────────────────────────────────────────────────────\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "x = range(len(results))\n",
        "w = 0.35\n",
        "ax.bar([i - w/2 for i in x], results['test_acc'], w, label='Test Accuracy')\n",
        "ax.bar([i + w/2 for i in x], results['test_f1'], w, label='Test Macro-F1')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(results['model'])\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Traditional ML — Hand-crafted Features')\n",
        "ax.legend()\n",
        "for i, (acc, f1) in enumerate(zip(results['test_acc'], results['test_f1'])):\n",
        "    ax.text(i - w/2, acc + 0.01, f'{acc:.3f}', ha='center', fontsize=8)\n",
        "    ax.text(i + w/2, f1 + 0.01, f'{f1:.3f}', ha='center', fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWh7rHuTvu6y"
      },
      "outputs": [],
      "source": [
        "# ── LaTeX table ───────────────────────────────────────────────────────\n",
        "lines = [\n",
        "    r'\\begin{table}[htbp]',\n",
        "    r'\\centering',\n",
        "    r'\\caption{Traditional ML results (hand-crafted features).}',\n",
        "    r'\\label{tab:svm-results}',\n",
        "    r'\\begin{tabular}{lrrrr}',\n",
        "    r'\\toprule',\n",
        "    r'\\textbf{Model} & \\textbf{Val Acc} & \\textbf{Val F1} & \\textbf{Test Acc} & \\textbf{Test F1} \\\\',\n",
        "    r'\\midrule',\n",
        "]\n",
        "for _, r in results.iterrows():\n",
        "    lines.append(\n",
        "        f\"{r['model']} & {r['val_acc']:.4f} & {r['val_f1']:.4f} & \"\n",
        "        f\"{r['test_acc']:.4f} & {r['test_f1']:.4f} \\\\\\\\\"\n",
        "    )\n",
        "lines += [r'\\bottomrule', r'\\end{tabular}', r'\\end{table}']\n",
        "\n",
        "tex = '\\n'.join(lines)\n",
        "print(tex)\n",
        "\n",
        "tex_path = config.RESULTS_DIR / 'svm_results.tex'\n",
        "tex_path.write_text(tex)\n",
        "print(f'\\nSaved {tex_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZHE3R1Qvu6y"
      },
      "outputs": [],
      "source": [
        "# Copy results to Drive\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "drive_results = Path('/content/drive/MyDrive/NNP_results')\n",
        "drive_results.mkdir(exist_ok=True)\n",
        "for f in config.RESULTS_DIR.iterdir():\n",
        "    shutil.copy2(f, drive_results / f.name)\n",
        "print(f'Copied results to {drive_results}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}